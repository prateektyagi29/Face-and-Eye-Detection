{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Face & Eye Detection using HAAR Cascade Classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "This work sample contains the face and eye recognition process of a test image.\n",
    "This is my third beginner project on Natural Language Processing where I am going to detect face and eye of a person from a sample image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "The sample image is a color image and I have converted it to gray scale because sheer complexity of coding and processing of colored images.\n",
    "Gray scale images are much easier and faster to process as compared to colored images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Hope you all will like it !"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing the packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing the packages\n",
    "\n",
    "import numpy as np\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing the classifier file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We point OpenCV's CascadeClassifier function to where our classifier (XML file format) is stored.\n",
    "# Uploading the classifier file.\n",
    "face_classifier = cv2.CascadeClassifier('C:\\\\Users\\\\Home\\\\Documents\\\\New folder\\\\ML-DL-NLP-Tableau\\\\OpenCV\\\\haarcascades\\\\haarcascade_frontalface_alt2.xml')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Importing the sample test image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uploading our sample image.\n",
    "image = cv2.imread('C:\\\\Users\\\\Home\\\\Documents\\\\New folder\\\\ML-DL-NLP-Tableau\\\\OpenCV\\\\testface.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now converting our sample image to grayscale.\n",
    "# We are converting RGB image to grayscale so as to reduce the complexity of code and image processing as the gray scale images are much easier to process as compared to colored images.\n",
    "# It is also important for learning image processing\n",
    "# As it's better to understand grayscale processing first and understand how it applies to multichannel processing rather than starting with full color imaging and missing all the important insights that can be learned from single channel processing.\n",
    "\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Developing face recognition algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Our classifier returns the ROI (Region of Interest) of the detected face as a tuple.\n",
    "# It stores the top left coordinate and the bottom right coordiantes\n",
    "\n",
    "# ROI or Region of Interest is dividing or partitioning a facial image into different regions so as to increase the overall accuracy\n",
    "\n",
    "faces = face_classifier.detectMultiScale(gray, 1.3, 5)\n",
    "\n",
    "# When no faces detected, face_classifier returns and empty tuple\n",
    "if faces is ():\n",
    "    print(\"No faces found\")\n",
    "\n",
    "# We iterate through our faces array and draw a rectangle\n",
    "# over each face in faces\n",
    "for (x,y,w,h) in faces:\n",
    "    cv2.rectangle(image, (x,y), (x+w,y+h), (127,0,255), 2)\n",
    "    cv2.imshow('Face Detection', image)\n",
    "    cv2.waitKey(0)\n",
    "    \n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# Here I have not given any specific command to destrot the popup window.\n",
    "# We can destroy or close the window either by pressing Enter key or Esc key or any key."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's combine face and eye detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Importing the classifier file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We point OpenCV's CascadeClassifier function to where our classifier (XML file format) is stored\n",
    "# Uploading the classifier file.\n",
    "# In this we use two classifier files, one for facial recognition and the other for eye recognition.\n",
    "\n",
    "face_classifier = cv2.CascadeClassifier('C:\\\\Users\\\\Home\\\\Documents\\\\New folder\\\\ML-DL-NLP-Tableau\\\\OpenCV\\\\haarcascades\\\\haarcascade_frontalface_alt2.xml')\n",
    "eye_classifier = cv2.CascadeClassifier('C:\\\\Users\\\\Home\\\\Documents\\\\New folder\\\\ML-DL-NLP-Tableau\\\\OpenCV\\\\haarcascades\\\\haarcascade_eye.xml')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Importing the sample image and converting it to gray scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Again Uploading our sample image and converting our sample image to grayscale.\n",
    "# We are converting RGB image to grayscale so as to reduce the complexity of code and image processing as the gray scale images are much easier to process as compared to colored images.\n",
    "\n",
    "img = cv2.imread('C:\\\\Users\\\\Home\\\\Documents\\\\New folder\\\\ML-DL-NLP-Tableau\\\\OpenCV\\\\testface.jpg')\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Developing face & eye recognition algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Our classifier returns the ROI (Region of Interest) of the detected face as a tuple.\n",
    "# It stores the top left coordinate and the bottom right coordiantes\n",
    "\n",
    "# ROI or Region of Interest is dividing or partitioning a facial image into different regions so as to increase the overall accuracy\n",
    "\n",
    "faces = face_classifier.detectMultiScale(gray, 1.2, 4)\n",
    "\n",
    "# When no faces detected, face_classifier returns and empty tuple\n",
    "if faces is ():\n",
    "    print(\"No Face Found\")\n",
    "\n",
    "    \n",
    "# We iterate through our faces array and draw a rectangle\n",
    "# over each face in faces\n",
    "for (x,y,w,h) in faces:\n",
    "    cv2.rectangle(img,(x,y),(x+w,y+h),(127,0,255),2)\n",
    "    #cv2.imshow('img',img)\n",
    "    #cv2.waitKey(0)\n",
    "    roi_gray = gray[y:y+h, x:x+w]\n",
    "    roi_color = img[y:y+h, x:x+w]  # Also converting eye color into gray scale as it is easier to process\n",
    "    eyes = eye_classifier.detectMultiScale(roi_gray)\n",
    "    for (ex,ey,ew,eh) in eyes:\n",
    "        cv2.rectangle(roi_color,(ex,ey),(ex+ew,ey+eh),(255,255,0),2)  # Now we iterate through eye array and draw a rectangle\n",
    "        cv2.imshow('img',img)\n",
    "        cv2.waitKey(0)\n",
    "    \n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# Here I have not given any specific command to destrot the popup window.\n",
    "# We can destroy or close the window either by pressing Enter key or Esc key or any key.\n",
    "\n",
    "#Disclaimer :-\n",
    "#If for some reason only one eye is being detected, press C key once. This will detect both the eyes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "This is a beginner approach I have carried out in detecting the face and eyes from a sample image and I have tried to attain maximum accuracy with the same.\n",
    "\n",
    "Hope You all liked it !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Any comments, suggestions are welcome\n",
    "\n",
    "\n",
    "Thank You !"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
